# drunk-chatbot

Proyecto de Machine Learning para el bootcamp de CORE Code School.

## Resumen

Se ha entrenado un modelo gpt-2 para ver si era capaz de responder imitando la manera de hablar de su creadora.

## Datos

Los datos que se han utilizado para entrenar el modelo son conversaciones exportadas de Whatsapp. Por razones de privacidad, este archivo no se encuentra en el repositorio, pero tenÃ­a 55k lÃ­neas de texto, etiquetadas como [ME] cuando se trataba de mensajes mÃ­os, y como [OTHERS] cuando eran de otras personas.

## Modelo

El modelo utilizado es uno ya existente, hecho ad-hoc para generaciÃ³n de texto. Se llama [gpt-2](https://github.com/openai/gpt-2), y pertenece a [OpenAI](https://openai.com/). Este modelo se ha utilizado mucho con textos en inglÃ©s, pero habÃ­a pocas pruebas con castellano. EncontrÃ© una de ellas en este [blog](https://planetachatbot.com/lo-que-aprendi-entrenando-al-primer-chatbot-gpt-2-en-espanol/), y decidÃ­ hacer una prueba personal.

El modelo se entrenÃ³ con el dataset arriba mencionado. El entrenamiento se completÃ³ en 18,5h, y el modelo resultante se puede descargar de [este link](https://drive.google.com/file/d/1HtE2MXuSD3fFhiKFlGMLOiNSu3SgIS3p/view?usp=sharing), con su correspondiente [checkpoint](https://drive.google.com/file/d/1VOgUCg4dpr9AnlsLt5WiAZg52M9BXEPp/view?usp=sharing).

## Resultados

Los resultados, con un Ãºnico entrenamiento y ese dataset, son bastante mejorables. Dejo aquÃ­ un extracto de algo del texto generado al azar.

`[ME] ğŸ‘ğŸ¼ğŸ‘ğŸ¼ğŸ‘ğŸ¼ğŸ‘ğŸ¼` 

`[ME] Â¡Ãnimo, Marta!` 

`[ME] Â¿EstÃ¡s en casa?`  

`[OTHERS] Ajajjajjajjajaj`  

`[OTHERS] Siii`  

`[OTHERS] Ya estoy`  

`[ME] Jajajajajajajaja`  

`[ME] Hoy estoy`  

`[ME] Marta, he ido a Misa en la farmacia, pero no me preocupen tener que ser en el grupo de secretarÃ­a`  

`[ME] Pero voy a intentar comprar una cerveza`  

`[ME] La verdad es que no me comprarÃ­a ningÃºn backlogado`  

`[ME] Marta, tengo que ir a comprarme unos dÃ­as para la cerveza`  

`[OTHERS] ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚`  

`[OTHERS] Muy bien`  

`[OTHERS] Jajajajajajajaj`  

`[ME] ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£`  

`[OTHERS] Ya me he hecho unos dÃ­as`  

`[OTHERS] Muy bien`  

`[ME] Ok`  

`[ME] Â¿CÃ³mo te encuentras?`  

`[OTHERS] En el grupo de secretarÃ­a`  

`[OTHERS] Pues eso te digo`  

`[ME] Â¡Estamos en el grupo!`  

`[OTHERS] Es una amiga de mi madre que tenÃ­a que hacerte fenomenal que van a mandar agosto`  

`[OTHERS] En el grupo sentido`  

`[OTHERS] Es para mÃ­`  

`[OTHERS] Que eso que he visto que en el grupo me encuentro`  

`[ME] Vale, sÃ­`  

`[ME] Â¿QuÃ© tal has visto a CÃ©sar?`  

`[OTHERS] AÃºn no me entiende, que me he costado mucho`  

`[OTHERS] ğŸ™ğŸ½ğŸ™ğŸ½ğŸ™ğŸ½ğŸ™ğŸ½ğŸ™`  

`[ME] ğŸ‘ğŸ¼ğŸ‘ğŸ¼ğŸ‘ğŸ¼ğŸ‘ğŸ¼ğŸ‘ğŸ¼ğŸ‘ğŸ¼`  

`[ME] Pues entonces no te preocupen`  

`[ME] Â¿En serio te has mandado?`  

`[ME] Porque maÃ±ana no sÃ© cuÃ¡nto, pero empezaron a entender que me habÃ­a metido en el mundo`  

`[OTHERS] Siii`  

`[OTHERS] Te lo has hecho ya??`  

`[ME] Lo he hecho es por la maÃ±ana`  

`[ME] Pero puedes aprovechadrar a Ana han cambiado el caso y he estado en el grupo de secretarÃ­a, porque me puedo quejar`  

`[OTHERS] Me ha dicho que ha sido a mi cambio y tambiÃ©n`

Como se ve, en funciÃ³n de los parÃ¡metros que se le pasen al modelo, se puede generar mÃ¡s o menos cantidad de texto, partiendo de un breve inicio. De primeras, el resultado es muy malo. Sin embargo, se pueden sacar algunas conclusiones:

1. El uso de signos de apertura en las interrogaciones (Â¿) y las exclamaciones (Â¡), que no son habituales en los chats informales y, sin embargo, yo los uso. Como se ve, siempre que [ME] pregunta o exclama, utiliza ambos signos, mientras que [OTHERS] no.
2. Lo mismo se puede decir del uso de las comas (,), mucho mÃ¡s abundante en los extractos correspondientes a [ME] que a [OTHERS].
3. Â¿Por quÃ© la conversaciÃ³n generada es tan caÃ³tica e inconexa? En el dataset pasado no habÃ­a ninguna referencia temporal, por lo que se podÃ­a haber entendido como una sola conversaciÃ³n larguÃ­sima. Si hubiera puesto algÃºn tipo de separador temporal, para delimitar mejor quÃ© frases responden a quÃ© frases, el modelo quizÃ¡ hubiera aprendido la relaciÃ³n entre unas frases y las posibles contestaciones.
4. Las referencias a Misas y cervezas indican que el modelo ha comprendido perfectamente por dÃ³nde van los tiros de mi vida.

## Mini-chatbot

Para aprovechar un poco el modelo, he hecho un pequeÃ±o chatbot con un back en Flask y un front en Streamlit. Como no estÃ¡ desplegado, dejo las instrucciones para levantarlo en local:

1. Installar `requirements.py` para ambos componentes.
2. Descargar el [checkpoint](https://drive.google.com/file/d/1VOgUCg4dpr9AnlsLt5WiAZg52M9BXEPp/view?usp=sharing), descomprimirlo y meterlo en la carpeta **src/controllers**.
3. Back: ir a directorio **src** y ejecutar: `python run server.py`
4. Front: ir a directorio **streamlit** y ejecutar: `streamlit run home.py`

## Extras

Este repositorio contiene algunos extras:

- Carpeta **jupyter**: contiene un par de Jupyter Notebooks para el pre-procesado de los chats de whatsapp, con la manera para convertirlos en un dataframe anonimizado.
- Carpeta **models**: contiene varios jupyter-notebook en los que se ven mis distintos intentos de entrenar modelos.
    - Basic_classification: utiliza un modelo secuencial entrenado con un dataset parecido para poder predecir si un texto lo he escrito yo u otra persona.
    - Chatbot: el entrenamiento del chatbot descrito arriba.
    - Classification_with_more_features: un intento de hacer una red con mÃ¡s de un input, pero no llegÃ³ a buen puerto.
    - Sentiment-analyzer: una prueba de concepto con un par de librerÃ­as para anÃ¡lisis de sentimientos, llegando a la conclusiÃ³n de que mis mensajes de whatsapp con bastante deprimentes.
